html <- read_html(url)
html
html |>
html_elements("table")
html |>
html_elements("table") |>
html_table()
tabelas[(3)]
tabelas <- html |>
html_elements("table") |>
html_table()
tabelas[(3)]
tabelas
tabelas[[3]]
tabelas[(3)]
View(tabelas[[3]])
alfabetizacao <- alfabetizacao[, c(2, 3)]
alfabetizacao <- tabelas[(3)]
tabelas[(3)]
View(tabelas[[3]])
alfabetizacao <- alfabetizacao[, c(2, 3)]
alfabetizacao <- tabelas[(3)]
tabelas[(3)]
View(tabelas[[3]])
alfabetizacao <- alfabetizacao[,c(2, 3)]
library(stringr)
alfabetizacao <- tabelas[[3]]
tabelas[[3]]
View(tabelas[[3]])
alfabetizacao <- alfabetizacao[,c(2, 3)]
names(alfabetizacao) <- c("estado", "taxa")
names(alfabetizacao)
url <- "https://pt.wikipedia.org/wiki/Lista_de_unidades_federativas_do_Brasil_por_alfabetiza%C3%A7%C3%A3o"
html <- read_html(url)
html
tabelas <- html |>
html_elements("table") |>
html_table()
alfabetizacao <- tabelas[[3]]
tabelas[[3]]
View(tabelas[[3]])
alfabetizacao <- alfabetizacao[,c(2, 3)]
names(alfabetizacao) <- c("estado", "taxa")
names(alfabetizacao)
str_replace_all(string = "pedro145", pattern = "\\d", replacement = "")
View(alfabetizacao)
alfabetizacao
print(alfabetizacao)
print(alfabetizacao)
library(rvest) # biblioteca utilizada para fazer a raspagem
library(dplyr) # bibliotea para manipular os dados
library(ggplot2)
url <- "https://pt.wikipedia.org/wiki/Lista_de_unidades_federativas_do_Brasil_por_alfabetiza%C3%A7%C3%A3o"
html <- read_html(url)
html
tabelas <- html |>
html_elements("table") |>
html_table()
alfabetizacao <- tabelas[[3]]
tabelas[[3]]
View(tabelas[[3]])
alfabetizacao <- alfabetizacao[,c(2, 3)]
names(alfabetizacao) <- c("estado", "taxa")
names(alfabetizacao)
library(stringr)
str_replace_all(string = "pedro145", pattern = ",", replacement = ".")
parte2 <- str_replace_all(string = parte1, pattern = "%", replacement = "")
library(stringr)
parte1 <- str_replace_all(string = "pedro145", pattern = ",", replacement = ".")
parte2 <- str_replace_all(string = parte1, pattern = "%", replacement = "")
parte_final <- as.numeric(parte2)
parte_final
parte_final <- parte_final / 100
library(stringr)
parte1 <- str_replace_all(string = alfabetizacao$taxa, pattern = ",", replacement = ".")
parte2 <- str_replace_all(string = parte1, pattern = "%", replacement = "")
parte_final <- as.numeric(parte2)
parte_final
parte_final <- parte_final / 100
library(stringr)
parte1 <- str_replace_all(string = alfabetizacao$taxa, pattern = ",", replacement = ".")
parte2 <- str_replace_all(string = parte1, pattern = "%", replacement = "")
parte_final <- as.numeric(parte2)
parte_final <- parte_final / 100
alfabetizacao$taxa <- parte_final
View(alfabetizacao)
library(geobr)
install.packages("geobr")
library(geobr)
library(geobr)
install.packages("geobr")
library(geobr)
minas <- read_state(code_state = "MG")
library(ggplot2)
ggplot(data = minas)+
geom_sf(fill = "darkblue")+
theme_void()
municipios_mg <- read_municipality(code_muni = "MG")
ggplot(data = municipios_mg)+
geom_sf()+
theme_void()
estados <- read_state()
View(alfabetizacao)
estados
estados$name_state
order(estados$name_state)
estados[2, ]
estados[2, ]
estados <- estados[order(estados$name_state),]
estados
alfabetizacao <- alfabetizacao[order(alfabetizacao$estado),]
# cria na tabela estado uma coluna taxa colocando os valoress de alfabetização
estados$taxa <- alfabetizacao$taxa
ggplot(data = estado, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "lightblue", low = "darkblue")
estados <- estados[order(estados$name_state),]
alfabetizacao <- alfabetizacao[order(alfabetizacao$estado),]
# cria na tabela estado uma coluna taxa colocando os valoress de alfabetização
estados$taxa <- alfabetizacao$taxa
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "lightblue", low = "darkblue")
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "darkblue", low = "lightblue")
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "#331F40", low = "#C13F99")
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "#331F40", low = "#C13F90")
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "#6A2473", low = "#C13F90")
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "#331F40", low = "#6A2470")
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "#331F10", low = "#6A2470")
ggplot(data = estados, aes(fill = taxa)) +
geom_sf() +
scale_fill_gradient(high = "#331F4F", low = "#6A2470")
# ****************  EXERCICIO 1 *************
# (a) (10, 11, 12,..., 30)
vetorA <- c()
contador <- 10
index <- 1
while (contador < 31) {
vetorA[index] <- contador
contador <- contador + 1
index <- index + 1
}
# (b) (30, 29, 28,..., 10)
vetorB <- c() # alocação dinâmica, que em alguns casos pode ser ineficiente
# vetorB <- numeric(21) -> pré alocação. Neste caso seria mais eficiente
contadorB <- 30
indexB <- 1
while (contadorB > 9) {
vetorB[indexB] = contadorB
contadorB <- contadorB - 1
indexB <- indexB + 1
}
# (c) (10, 11, 12,..., 30, 29, 28,..., 10)
vetorC <- c(vetorA, vetorB)
vetorA
vetorC
library(rvest)
library(dplyr)
library(tidytext)
library(tidyr) # organizar um conjunto
library(ggplot2)
library(stopwords)
install.packages("stopwords")
library(stopwords)
library(dplyr)
library(rvest)
library(tidytext)
library(tidyr) # organizar um conjunto
library(ggplot2)
library(stopwords)
library(rvest) # raspar dados
library(stringr)
library(janeaustenr) # todos livros da jane austen
url <- "https://www.bbc.com/portuguese/articles/c3dv8yy3d8jo"
html <- read_html(url)
html
noticia <- html |>
html_elements("p.bbc-hhl7in") |>
html_text2()
noticia
noticia <- paste(noticia, collapse = " ")
noticia
artigos |>
unnest_tokens(output = words, input = noticia) |>
count(words, sort = TRUE) |>
top_n(10) # pega as 10 palavras mais frequentes
artigos <- data.frame(noticia)
artigos |>
unnest_tokens(output = words, input = noticia) |>
count(words, sort = TRUE) |>
top_n(10) # pega as 10 palavras mais frequentes
stopwords_br <- data.frame(word = stopwords("pt"))
frequentes <- artigos |>
unnest_tokens(output = word, input = noticia) |>
anti_join(stopwords_br) |>
count(word, sort = TRUE) |>
top_n(10) |>
mutate(word = reorder(word, n))
ggplot(frequentes, aes(x = n, y = word)) +
geom_col(fill = "orangered4") +
theme_minimal()
livro <- prideprejudice # todo orgulho e preconceito
conjunto2 <- data.frame(livro)
stopword_en <- data.frame(word = stopwords("en"))
conjunto2 |>
unnest_tokens(output = word, input = livro) |>
anti_join(stopword_en) |>
count(word, sort = TRUE) |>
top_n(10) |>
mutate(word = reorder(word, n))
ggplot(frequentes_livro, aes(x = n, y = word)) +
geom_col(fill = "lightblue") +
theme_minimal()
ggplot(frequentes, aes(x = n, y = word)) +
geom_col(fill = "lightblue") +
theme_minimal()
sentimentos <- get_sentiments("bing")
capitulos <- str_detect(conjunto2$livro, "^Chapter \\d+")
capitulos <- cumsum(capitulos)
conjunto2 |>
mutate(capitulo = capitulos) |>
unnest_tokens(word, livro) |>
inner_join(sentimentos) |>
count(capitulo, sentiment) |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capitulo, y = total, fill = total > 0)) +
geom_col() +
theme_minimal()
library(janeaustenr)
library(tidytext)
library(dplyr)
library(dplyr)
library(ggplot2)
library(srtingr)
library(stringr)
library(stopwords)
livros <- austen_books()
unique(livros$book)
livros |>
filter(book == "Emma")
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
count(word, sort = TRUE) |>
top_n(10)
stop_words("en")
stopwords("en")
stopwords_en() <- data.frame(word = stopwords("en"))
stopwords_en <- data.frame(word = stopwords("en"))
livros |>
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
count(word, sort = TRUE) |>
top_n(10)
livros |>
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
count(word, sort = TRUE) |>
anti_join(stopwords_en)
livros |>
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
anti_join(stopwords_en) |>
count(word, sort = TRUE) |>
top_n(10)
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
anti_join(stopwords_en) |>
count(word, sort = TRUE) |>
top_n(10)
livros |>
filter(book == "Emma") |>
print(n = 20)
capitulos <- str_detect(livros)
livros |>
filter(book == "Emma")
capitulos <- str_detect(emma$text, "^ĈHAPTER")
capitulos
capitulos <- str_detect(emma$text, "^ĈHAPTER")
emma |>
filter(book == "Emma")
emma <- livros |>
filter(book == "Emma")
capitulos <- str_detect(emma$text, "^ĈHAPTER [IVXLCDM]+")
capitulos
capitulos <- cumsum(capitulos)
capitulos
emma$capitulos <- capitulos
str(emma)
which(capitulos)
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"))
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing")) |>
count(capitulos, sentiment)
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing")) |>
count(capitulos, sentiments)
capitulos <- str_detect(emma$text, "^ĈHAPTER [IVXLCDM]+")
capitulos <- cumsum(capitulos)
capitulos
emma$capitulos <- capitulos
str(emma)
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing")) |>
count(capitulos, sentiment)
library(tidyr)
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing")) |>
count(capitulos, sentiment)
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing")) |>
count(capitulos, sentiment)
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing")) |>
count(capitulos, sentiment) |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capitulos), y = total))+geom_col()
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing")) |>
count(capitulos, sentiment) |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capitulos, y = total))+geom_col()
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
count(capitulos, sentiment) |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capitulos, y = total))+geom_col()
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
count(capitulos, sentiment) |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capitulos, y = total))+
geom_col()
stopwords_en <- data.frame(word = stopwords("en"))
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
anti_join(stopwords_en) |>
count(word, sort = TRUE) |>
top_n(10)
emma <- livros |>
filter(book == "Emma")
capitulos <- str_detect(emma$text, "^ĈHAPTER [IVXLCDM]+")
capitulos <- cumsum(capitulos)
capitulos
emma$capitulos <- capitulos
str(emma)
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
count(capitulos, sentiment) |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capitulos, y = total))+
geom_col()
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE))))
emma |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
count(capitulos, sentiment) |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capitulos, y = total))+
geom_col()
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE)))) |>
ungroup() |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capiulos, y = total, fill = book))+
geom_col(show.legend = FALSE) +
facet_wrap(~book)
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE)))) |>
ungroup() |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capiulos, y = total, fill = book))+
geom_col(show.legend = FALSE) +
facet_wrap(~book, )
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE)))) |>
ungroup() |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capiulos, y = total, fill = book))+
geom_col(show.legend = FALSE) +
facet_wrap(~book, )
stopwords_en <- data.frame(word = stopwords("en"))
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE)))) |>
ungroup() |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capiulos, y = total, fill = book))+
geom_col(show.legend = FALSE) +
facet_wrap(~book, scale = "free_x")
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
anti_join(stopwords_en) |>
count(word, sort = TRUE) |>
top_n(10)
stopwords_en <- data.frame(word = stopwords("en"))
livros |>
filter(book == "Emma") |>
unnest_tokens(output =  word, input = text) |>
anti_join(stopwords_en) |>
count(word, sort = TRUE) |>
top_n(10)
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE)))) |>
ungroup() |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capiulos, y = total, fill = book))+
geom_col(show.legend = FALSE) +
facet_wrap(~book, scale = "free_x")
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE)))) |>
ungroup() |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capiulos, y = total, fill = book))+
geom_col(show.legend = FALSE) +
facet_wrap(~book, scale = "free_x")
livros |>
group_by(book) |>
mutate(capitulos = cumsum(str_detect(text, regex("^chapter (\\d+|[IVXCDLM])", ignore_case = TRUE)))) |>
ungroup() |>
unnest_tokens(word, text) |>
anti_join(stopwords_en) |>
inner_join(get_sentiments("bing"), relationship = "many-to-many") |>
spread(sentiment, n, fill = 0) |>
mutate(total = positive - negative) |>
ggplot(aes(x = capiulos, y = total, fill = book))+
geom_col(show.legend = FALSE) +
facet_wrap(~book, scales = "free_x")
femur <- read.csv("femur.csv")
setwd("~/Documents/R-language/Aulas")
femur <- read.csv("femur.csv")
str(femur)
